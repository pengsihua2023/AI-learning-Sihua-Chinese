明白 ✅ 我保持内容不变，只是把公式部分全部改为 GitHub 上能正常显示的 LaTeX 格式（即 `$$ ... $$`），并保留三种散度：

---

# 散度及其在深度学习中的应用

## 1. 什么是散度？

在数学和信息论中，**散度 (Divergence)** 通常指的是两个概率分布之间的差异度量。

### (1) Kullback–Leibler 散度 (KL Divergence)

离散型：


$$
D_{\mathrm{KL}}(P \parallel Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}
$$


连续型：

```markdown
$$
D_{\mathrm{KL}}(P \parallel Q) = \int P(x) \log \frac{P(x)}{Q(x)} \, dx
$$
```

---

### (2) Jensen–Shannon 散度 (JS Divergence)

```markdown
$$
D_{\mathrm{JS}}(P \parallel Q) = \tfrac{1}{2} D_{\mathrm{KL}}(P \parallel M) 
+ \tfrac{1}{2} D_{\mathrm{KL}}(Q \parallel M), 
\quad M = \tfrac{1}{2}(P+Q)
$$
```

---

### (3) Wasserstein 距离 (Earth Mover’s Distance)

描述为“将一个分布变成另一个分布所需的最小搬运代价”。常见于生成对抗网络 (WGAN) 中。

---

## 2. 散度在深度学习中的应用

### (1) 损失函数 (Loss Function)

交叉熵损失：

```markdown
$$
H(P,Q) = H(P) + D_{\mathrm{KL}}(P \parallel Q)
$$
```

---

### (2) 生成模型 (Generative Models)

**变分自编码器 (VAE):**

```markdown
$$
\mathcal{L}_{VAE} = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] 
- D_{\mathrm{KL}}(q_\phi(z|x) \parallel p(z))
$$
```

**生成对抗网络 (GAN):**

* 原始 GAN：最小化 JS 散度
* WGAN：最小化 Wasserstein 距离

---

### (3) 分布匹配 (Distribution Matching)

知识蒸馏 (Knowledge Distillation)：

```markdown
$$
\min_\theta D_{\mathrm{KL}}(P \parallel Q)
$$
```

其中 $P$ 为教师网络分布，$Q$ 为学生网络分布。

---

### (4) 强化学习 (Reinforcement Learning)

策略优化方法（如 TRPO, PPO）中，常用 KL 散度来约束新旧策略的差异：

```markdown
$$
D_{\mathrm{KL}}(\pi_{\text{old}} \parallel \pi_{\text{new}}) \leq \delta
$$
```



