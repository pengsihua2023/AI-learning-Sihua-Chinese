## 高级：自监督学习
自监督学习（Self-Supervised Learning，SSL）是一种机器学习范式，它从无标签数据中自动生成伪标签（pretext tasks）来进行训练，从而学习有用的表示，而不需要人工标注的标签。这与传统的无监督学习不同，后者通常直接从数据中发现模式（如聚类），而自监督学习更像“监督”自己生成的任务。相比监督学习，它能更好地利用海量无标签数据，尤其在计算机视觉、自然语言处理等领域应用广泛。
对比学习（Contrastive Learning）也是自监督学习的一种典型类型。它通过将相似样本（正样本对）拉近、不同样本（负样本对）推远来学习表示，例如SimCLR或MoCo算法。

根据主流分类，自监督学习可以分为以下几类。这些分类基于任务设计和学习机制，可能有重叠，但有助于理解。
<img width="1235" height="1025" alt="image" src="https://github.com/user-attachments/assets/86c7af28-5fc7-4e65-a742-63146b6de698" />  

这些类型不是严格互斥的，许多现代方法（如在视觉或NLP中）会结合多种机制。例如，在2024-2025年的研究中，自监督学习越来越多地应用于多模态（如CLIP的扩展）和联邦学习场景。 
