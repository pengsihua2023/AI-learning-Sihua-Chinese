## 高级：自监督学习
自监督学习（Self-Supervised Learning，SSL）是一种机器学习范式，它从无标签数据中自动生成伪标签（pretext tasks）来进行训练，从而学习有用的表示，而不需要人工标注的标签。这与传统的无监督学习不同，后者通常直接从数据中发现模式（如聚类），而自监督学习更像“监督”自己生成的任务。相比监督学习，它能更好地利用海量无标签数据，尤其在计算机视觉、自然语言处理等领域应用广泛。
对比学习（Contrastive Learning）也是自监督学习的一种典型类型。它通过将相似样本（正样本对）拉近、不同样本（负样本对）推远来学习表示，例如SimCLR或MoCo算法。

根据主流分类，自监督学习可以分为以下几类。这些分类基于任务设计和学习机制，可能有重叠，但有助于理解。
<img width="1235" height="1025" alt="image" src="https://github.com/user-attachments/assets/86c7af28-5fc7-4e65-a742-63146b6de698" />  

这些类型不是严格互斥的，许多现代方法（如在视觉或NLP中）会结合多种机制。例如，在2024-2025年的研究中，自监督学习越来越多地应用于多模态（如CLIP的扩展）和联邦学习场景。 

## Code
```
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt

class RotationPredictor(nn.Module):
    """旋转预测自监督学习模型"""
    def __init__(self, input_dim=784, hidden_dim=128, num_classes=4):
        super(RotationPredictor, self).__init__()
        self.feature_extractor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
        )
        self.classifier = nn.Linear(hidden_dim, num_classes)
        
    def forward(self, x):
        # 将输入展平
        x = x.view(x.size(0), -1)
        # 提取特征
        features = self.feature_extractor(x)
        # 预测旋转角度
        rotation_pred = self.classifier(features)
        return rotation_pred, features

def create_rotation_dataset(images, labels):
    """
    创建旋转预测数据集
    Args:
        images: 原始图像
        labels: 原始标签
    Returns:
        rotated_images: 旋转后的图像
        rotation_labels: 旋转角度标签 (0, 90, 180, 270度)
    """
    rotated_images = []
    rotation_labels = []
    
    for image in images:
        # 创建4个旋转版本
        for rotation in range(4):
            angle = rotation * 90
            # 使用torchvision的旋转变换
            transform = transforms.Compose([
                transforms.ToPILImage(),
                transforms.RandomRotation([angle, angle]),
                transforms.ToTensor()
            ])
            rotated_img = transform(image)
            rotated_images.append(rotated_img)
            rotation_labels.append(rotation)
    
    return torch.stack(rotated_images), torch.tensor(rotation_labels)

def train_rotation_predictor(model, train_loader, num_epochs=5, device='cpu'):
    """训练旋转预测模型"""
    model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    
    train_losses = []
    train_accuracies = []
    
    print("开始旋转预测自监督训练...")
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0.0
        total_correct = 0
        total_samples = 0
        num_batches = 0
        
        for batch_idx, (images, _) in enumerate(train_loader):
            images = images.to(device)
            
            # 创建旋转数据集
            rotated_images, rotation_labels = create_rotation_dataset(images, _)
            rotated_images = rotated_images.to(device)
            rotation_labels = rotation_labels.to(device)
            
            # 前向传播
            rotation_pred, _ = model(rotated_images)
            
            # 计算损失
            loss = criterion(rotation_pred, rotation_labels)
            
            # 反向传播
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # 计算准确率
            _, predicted = torch.max(rotation_pred, 1)
            total_correct += (predicted == rotation_labels).sum().item()
            total_samples += rotation_labels.size(0)
            
            total_loss += loss.item()
            num_batches += 1
            
            if batch_idx % 50 == 0:
                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}, Loss: {loss.item():.4f}')
        
        avg_loss = total_loss / num_batches
        avg_accuracy = total_correct / total_samples
        train_losses.append(avg_loss)
        train_accuracies.append(avg_accuracy)
        
        print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.4f}')
    
    return train_losses, train_accuracies

def evaluate_downstream_task(model, test_loader, device='cpu'):
    """评估下游任务（数字分类）"""
    model.eval()
    
    # 提取特征
    features = []
    labels = []
    
    with torch.no_grad():
        for images, targets in test_loader:
            images = images.to(device)
            # 提取特征（使用0度旋转）
            _, batch_features = model(images)
            features.append(batch_features.cpu())
            labels.append(targets)
    
    features = torch.cat(features, dim=0)
    labels = torch.cat(labels, dim=0)
    
    # 训练简单的线性分类器
    linear_classifier = nn.Linear(features.size(1), 10).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(linear_classifier.parameters(), lr=0.01)
    
    # 划分训练集和验证集
    split_idx = int(0.8 * len(features))
    train_features = features[:split_idx].to(device)
    train_labels = labels[:split_idx].to(device)
    val_features = features[split_idx:].to(device)
    val_labels = labels[split_idx:].to(device)
    
    # 训练线性分类器
    for epoch in range(15):
        linear_classifier.train()
        optimizer.zero_grad()
        outputs = linear_classifier(train_features)
        loss = criterion(outputs, train_labels)
        loss.backward()
        optimizer.step()
        
        if epoch % 5 == 0:
            # 验证
            linear_classifier.eval()
            with torch.no_grad():
                val_outputs = linear_classifier(val_features)
                val_loss = criterion(val_outputs, val_labels)
                _, predicted = torch.max(val_outputs, 1)
                accuracy = (predicted == val_labels).float().mean()
                print(f'Downstream Task Epoch {epoch}, Val Loss: {val_loss:.4f}, Val Acc: {accuracy:.4f}')
    
    return accuracy.item()

def visualize_rotation_predictions(model, test_loader, device='cpu', num_samples=8):
    """可视化旋转预测结果"""
    model.eval()
    
    # 获取一批数据
    images, _ = next(iter(test_loader))
    images = images[:num_samples].to(device)
    
    # 创建旋转版本
    rotated_images, rotation_labels = create_rotation_dataset(images, _)
    rotated_images = rotated_images.to(device)
    rotation_labels = rotation_labels.to(device)
    
    with torch.no_grad():
        rotation_pred, _ = model(rotated_images)
        _, predicted = torch.max(rotation_pred, 1)
    
    # 可视化结果
    fig, axes = plt.subplots(num_samples, 4, figsize=(12, 3*num_samples))
    angles = ['0°', '90°', '180°', '270°']
    
    for i in range(num_samples):
        for j in range(4):
            idx = i * 4 + j
            img = rotated_images[idx].cpu().squeeze()
            true_angle = rotation_labels[idx].item()
            pred_angle = predicted[idx].item()
            
            axes[i, j].imshow(img, cmap='gray')
            axes[i, j].set_title(f'True: {angles[true_angle]}, Pred: {angles[pred_angle]}')
            axes[i, j].axis('off')
    
    plt.tight_layout()
    plt.savefig('rotation_predictions.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_training_curves(losses, accuracies):
    """绘制训练曲线"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # 损失曲线
    ax1.plot(losses, 'b-o', linewidth=2, markersize=6)
    ax1.set_title('旋转预测训练损失', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.grid(True, alpha=0.3)
    
    # 准确率曲线
    ax2.plot(accuracies, 'r-o', linewidth=2, markersize=6)
    ax2.set_title('旋转预测准确率', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('Accuracy', fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 1)
    
    plt.tight_layout()
    plt.savefig('rotation_training_curves.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    """主函数"""
    # 设置设备
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用设备: {device}")
    
    # 加载MNIST数据集
    print("加载MNIST数据集...")
    transform = transforms.Compose([
        transforms.ToTensor(),
    ])
    
    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
    
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)
    
    # 创建模型
    model = RotationPredictor(input_dim=784, hidden_dim=128, num_classes=4)
    print(f"模型参数数量: {sum(p.numel() for p in model.parameters()):,}")
    
    # 训练自监督模型
    print("开始旋转预测自监督学习训练...")
    train_losses, train_accuracies = train_rotation_predictor(model, train_loader, num_epochs=5, device=device)
    
    # 绘制训练曲线
    plot_training_curves(train_losses, train_accuracies)
    
    # 可视化旋转预测结果
    print("可视化旋转预测结果...")
    visualize_rotation_predictions(model, test_loader, device=device)
    
    # 评估下游任务
    print("评估下游任务（数字分类）...")
    downstream_accuracy = evaluate_downstream_task(model, test_loader, device=device)
    print(f"下游任务准确率: {downstream_accuracy:.4f}")
    
    # 保存模型
    torch.save(model.state_dict(), 'rotation_predictor_model.pth')
    print("模型已保存到: rotation_predictor_model.pth")
    
    print("旋转预测自监督学习完成！")

if __name__ == "__main__":
    main()
```
