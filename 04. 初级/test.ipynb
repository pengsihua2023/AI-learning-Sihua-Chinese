{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "e0144571", "cell_type": "markdown", "source": "# 变分自编码器 (Variational Autoencoder, VAE)\n\n本文档给出 VAE 的数学描述，包括其基本原理、目标函数以及推导。", "metadata": {}}, {"id": "1fb2a477", "cell_type": "markdown", "source": "## 数学描述\n\nVAE 是一种生成模型，其目标是学习潜在变量 $z$ 的分布，从而能够生成与训练数据分布相似的样本。\n\n1. **生成模型假设**:\n$$ p_\theta(x, z) = p_\theta(x|z) p(z) $$\n\n其中 $p(z)$ 通常取为标准正态分布 $\\mathcal{N}(0, I)$。\n\n2. **变分推断**:\n由于后验分布 $p_\theta(z|x)$ 难以直接计算，我们用一个可参数化的分布 $q_\\phi(z|x)$ 近似：\n$$ q_\\phi(z|x) \\approx p_\theta(z|x) $$\n\n3. **证据下界 (ELBO)**:\n对数似然为：\n$$ \\log p_\\theta(x) = D_{KL}(q_\\phi(z|x) || p_\\theta(z|x)) + \\mathcal{L}(\\theta, \\phi; x) $$\n\n其中 ELBO (Evidence Lower BOund) 为：\n$$ \\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z|x)} [ \\log p_\\theta(x|z) ] - D_{KL}(q_\\phi(z|x) || p(z)) $$\n\n最大化 ELBO 等价于最小化重构误差和 KL 散度。", "metadata": {}}, {"id": "1c16f648", "cell_type": "markdown", "source": "## 参数化与重参数化技巧\n\n为了能够反向传播梯度，VAE 使用重参数化技巧：\n\n$$ z = \\mu(x) + \\sigma(x) \\odot \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, I) $$\n\n其中 $\\mu(x), \\sigma(x)$ 由编码器网络输出。", "metadata": {}}, {"id": "df09f74e", "cell_type": "markdown", "source": "## 最终目标函数\n\n对每个样本 $x$，优化目标为：\n\n$$ \\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_\\phi(z|x)} [ \\log p_\\theta(x|z) ] - D_{KL}(q_\\phi(z|x) || p(z)) $$\n\n其中：\n- 第一项是重构误差 (通常是交叉熵或均方误差)。\n- 第二项是 KL 散度，约束近似后验分布接近先验分布。", "metadata": {}}]}
